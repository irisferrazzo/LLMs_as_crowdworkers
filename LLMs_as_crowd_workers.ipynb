{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Acting Like Humans? Evaluating Large Language Models as Proxies in Linguistic Experiments\n",
        "\n",
        "\n",
        "This notebook refers to the paper ***Acting Like Humans? Evaluating Large Language Models as Proxies in Linguistic Experiments***, which aims to replicate linguistic experimental pipelines with human participants using LLMs.\n",
        "\n",
        "\n",
        "It is intended to be used for further research.\n",
        "\n"
      ],
      "metadata": {
        "id": "9O2ZpQ84chnQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code structure: #\n",
        "\n",
        "In the **first block** of the code, some libraries (such as openai) are imported and the own API-key of OpenAI is defined."
      ],
      "metadata": {
        "id": "DeGwUaQhWxOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\" # insert here OpenAI API key"
      ],
      "metadata": {
        "id": "gpj-Y4VqO-Jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **second block** of the code contains the prompt engineering functions that we will use later. You will find zero and few shot prompting as example functions. However, only the zero-shot function is applied in the next steps, since few-shot prompting performed poorely in first pilot studies."
      ],
      "metadata": {
        "id": "xyvUbo_iZ76e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for Zero-Shot Prompting\n",
        "def zero_shot_prompting(task, prompt):\n",
        "    \"\"\"\n",
        "    Performs zero-shot prompting by sending a prompt to the language model\n",
        "    without providing any previous examples.\n",
        "\n",
        "    Args:\n",
        "    task (str): The task to be performed.\n",
        "    prompt (str): The text to be sent as input to the language model.\n",
        "\n",
        "    Returns:\n",
        "    str: The response from the language model.\n",
        "    \"\"\"\n",
        "    # Creating the chat message and sending it to the language model\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an assistant\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    # Returning the content of the first response message from the model\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "\n",
        "# Function for Few-Shot Prompting\n",
        "def few_shot_prompting(task, examples, prompt):\n",
        "    \"\"\"\n",
        "    Performs few-shot prompting by providing some examples before sending the actual\n",
        "    prompt to the language model.\n",
        "\n",
        "    Args:\n",
        "    task (str): The task to be performed.\n",
        "    examples (list of dict): A list of examples, where each example is a dictionary\n",
        "                              containing 'input' and 'output' keys.\n",
        "    prompt (str): The text to be sent as input to the language model.\n",
        "\n",
        "    Returns:\n",
        "    str: The response from the language model.\n",
        "    \"\"\"\n",
        "    # Initializing the messages list with a system message\n",
        "    messages = [{\"role\": \"system\", \"content\": \"You are an assistant\"}]\n",
        "\n",
        "    # Adding the examples to the messages\n",
        "    for example in examples:\n",
        "        messages.append({\"role\": \"user\", \"content\": example['input']})\n",
        "        messages.append({\"role\": \"assistant\", \"content\": example['output']})\n",
        "\n",
        "    # Adding the actual prompt to the messages list\n",
        "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "    # Creating the chat message and sending it to the language model\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=messages\n",
        "    )\n",
        "    # Returning the content of the first response message from the model\n",
        "    return response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "hjmUVUACL8wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Replication pipeline step 1"
      ],
      "metadata": {
        "id": "eqM4xtBINj5q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the **third block** of the code you find code so that you can read in your uploaded data. This will be helpful in presenting the data to the LLM during prompting.\n",
        "\n",
        "Data handling code is provided for both replications. According to the data read in the cell, choose the corresponding passage and comment the other one out."
      ],
      "metadata": {
        "id": "OCAGXMgKadMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import json\n",
        "import gc\n",
        "from psutil import virtual_memory\n",
        "from datetime import datetime\n",
        "\n",
        "# Load data\n",
        "daten = 'Lombard_replicat_appendix.csv'  # Adjust the filename as needed\n",
        "df = pd.read_csv(daten)\n",
        "shuffled_df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Data handling for replication 1 (Cruz_23)\n",
        "columns_to_extract = ['sentences', 'target_item ', 'animacy', 'congruent-gender', 'status']\n",
        "selected_data = shuffled_df[columns_to_extract].astype(str)\n",
        "stimuli_dict = selected_data.to_dict(orient=\"index\")\n",
        "\n",
        "all_items=list()\n",
        "print(\"The materials for the study are:\")\n",
        "for entry in stimuli_dict.values():\n",
        "    all_items.append(entry['sentences'])\n",
        "print(all_items[:5])\n",
        "\n",
        "'''# Data handling for replication 2 (Lombard_21)\n",
        "columns_to_extract = ['change', 'regularity', 'process', 'neologism', 'target_sent']\n",
        "selected_data = shuffled_df[columns_to_extract].astype(str)\n",
        "stimuli_dict = selected_data.to_dict(orient=\"index\")\n",
        "\n",
        "# Create list of items\n",
        "all_items = [entry['target_sent'] for entry in stimuli_dict.values()]\n",
        "print(\"The materials for the study are:\")\n",
        "print(all_items)'''"
      ],
      "metadata": {
        "id": "5rDs7Gpugynz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Replication pipeline step 2"
      ],
      "metadata": {
        "id": "c5rN-o8fNsc8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the **fourth block** we can apply the prompt engineering functions of block 2. We will formulate our prompts in this cell. In this block, we can test different prompting strategies on one LLM-query and on a limited subset of the dataset."
      ],
      "metadata": {
        "id": "RVADzDhrcHx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To test one \"LLM-participant\" with a subset of the items\n",
        "\n",
        "# Preparing to store the model's responses\n",
        "answers_zero_shot = {}\n",
        "\n",
        "# === Zero-Shot Prompting ===\n",
        "print(\"=== Zero-Shot ===\")\n",
        "\n",
        "# Iterating through the subset for Zero-Shot\n",
        "for i, text in enumerate(all_items[:3]):\n",
        "    zero_shot_prompt = f\"Insert your instructions here: '{text}'\"\n",
        "\n",
        "    # Performing Zero-Shot Prompting\n",
        "    zero_shot = zero_shot_prompting(\"Task description\", zero_shot_prompt)\n",
        "\n",
        "    # Storing the response in the dictionary with the index as the key\n",
        "    answers_zero_shot[i] = {\n",
        "        \"Prompt\": zero_shot_prompt,\n",
        "        \"Response\": zero_shot\n",
        "    }\n",
        "\n",
        "    # Printing the input and the corresponding output\n",
        "    print(f\"Input: {text}\")\n",
        "    print(f\"Output: {zero_shot}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "RGt5oGzMVnrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the **fifth block** we save the results in an Excel file. This file stores the answers of ***ONE*** LLM-participant."
      ],
      "metadata": {
        "id": "rT3E2kchAorJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here to store the responses of ++ONE++ PARTICIPANT\n",
        "\n",
        "import pandas as pd\n",
        "import openpyxl\n",
        "from openpyxl.utils import get_column_letter\n",
        "from datetime import datetime\n",
        "import csv\n",
        "\n",
        "\n",
        "def convert_csv_to_excel(csv_path, excel_path):\n",
        "    \"\"\"\n",
        "    Converts a CSV file into an Excel file (.xlsx).\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(csv_path)\n",
        "    df.to_excel(excel_path, index=False)\n",
        "\n",
        "def load_or_create_excel(file_path):\n",
        "    \"\"\"\n",
        "    Loads an existing Excel file or creates a new one if the file does not exist.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        workbook = openpyxl.load_workbook(file_path)\n",
        "        sheet = workbook.active\n",
        "    except FileNotFoundError:\n",
        "        workbook = openpyxl.Workbook()\n",
        "        sheet = workbook.active\n",
        "        print(f\"File '{file_path}' not found. This is an error, check the name of the file uploaded in Block 3.\")\n",
        "    return workbook, sheet\n",
        "\n",
        "def add_columns_to_excel(sheet, new_columns):\n",
        "    \"\"\"\n",
        "    Adds new columns to the Excel file.\n",
        "    \"\"\"\n",
        "    existing_columns = sheet.max_column\n",
        "    for idx, col_name in enumerate(new_columns, start=existing_columns + 1):\n",
        "        sheet[f\"{get_column_letter(idx)}1\"] = col_name\n",
        "\n",
        "def add_data_to_excel(sheet, data_dict, start_row):\n",
        "    \"\"\"\n",
        "    Adds the contents of a dictionary to the Excel sheet.\n",
        "    \"\"\"\n",
        "    for idx, (key, entry) in enumerate(data_dict.items(), start=start_row):\n",
        "        sheet[f\"A{idx}\"] = key + 1\n",
        "        sheet[f\"B{idx}\"] = entry['Response']\n",
        "        sheet[f\"C{idx}\"] = entry['Prompt']\n",
        "        sheet[f\"D{idx}\"] = entry['Response_Original']\n",
        "        sheet[f\"E{idx}\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    print(\"Data added.\")\n",
        "\n",
        "def save_excel(workbook, file_path):\n",
        "    \"\"\"\n",
        "    Saves the workbook to the specified file.\n",
        "    \"\"\"\n",
        "    workbook.save(file_path)\n",
        "    print(f\"File successfully saved at: {file_path}\")\n",
        "\n",
        "def extend_csv(csv_input_path, csv_output_path, data_dict):\n",
        "    \"\"\"\n",
        "    Extends a CSV file by adding new columns and saves it as a new CSV file.\n",
        "    \"\"\"\n",
        "    with open(csv_input_path, mode='r', newline='') as infile, open(csv_output_path, mode='w', newline='') as outfile:\n",
        "        reader = csv.DictReader(infile)\n",
        "        fieldnames = reader.fieldnames + [\"Prompt\", \"Response_from_Model\", \"Date\"]\n",
        "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
        "\n",
        "        writer.writeheader()\n",
        "\n",
        "        # Only process as many rows as there are entries in the data_dict\n",
        "        for idx, row in enumerate(reader):\n",
        "            if idx < len(data_dict):  # Process only if there is a corresponding entry in the dictionary\n",
        "                row[\"Prompt\"] = data_dict[idx][\"Prompt\"]\n",
        "                row[\"Response_from_Model\"] = data_dict[idx][\"Response\"]\n",
        "                row[\"Date\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "                writer.writerow(row)\n",
        "\n",
        "    print(f\"Extended CSV file saved at: {csv_output_path}\")\n",
        "\n",
        "\n",
        "# --- Parameters ---\n",
        "csv_file_path = daten\n",
        "excel_file_path = \"results_one_participant.xlsx\"\n",
        "csv_output_path = \"results_one_participant.csv\"\n",
        "# 1. Convert CSV -> Excel and extend it\n",
        "convert_csv_to_excel(csv_file_path, excel_file_path)\n",
        "workbook, sheet = load_or_create_excel(excel_file_path)\n",
        "add_columns_to_excel(sheet, [\"Prompt\", \"Response_from_Model\", \"Date\"])\n",
        "add_data_to_excel(sheet, answers_zero_shot, start_row=sheet.max_row + 1)\n",
        "save_excel(workbook, excel_file_path)\n",
        "\n",
        "# 2. Alternatively: Extend CSV directly\n",
        "extend_csv(csv_file_path, csv_output_path, answers_zero_shot)\n"
      ],
      "metadata": {
        "id": "KnkgSGIIAnG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Replication pipeline step 3"
      ],
      "metadata": {
        "id": "iKqQ_-KhNu71"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the **sixth block** we repeat the prompting that worked best for as many times as we have (or want to have) subjects and with all data in the corpus."
      ],
      "metadata": {
        "id": "6ohvcW9YI5O2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompting with all participants and the entire corpus\n",
        "\n",
        "answers_null_shot_all = {}\n",
        "number_of_participants = 10\n",
        "reaction_time_per_participant = list()\n",
        "\n",
        "import time  # Import the time module\n",
        "\n",
        "for iteration in range(1, number_of_participants + 1):  # Repeat the process for each participant\n",
        "    print(f\"### LLM-informant {iteration} ###\")\n",
        "\n",
        "    answers_null_shot = {}  # Dictionary to store null-shot responses for this iteration\n",
        "\n",
        "    # === Null-Shot ===\n",
        "    # Record the start time for the participant\n",
        "    start_time_for_participant = time.time()\n",
        "\n",
        "    for i, text in enumerate(all_items):  # Iterate through each item in the corpus\n",
        "        start_time = time.time()  # Record the start time for each prompt\n",
        "        zero_shot_prompt = f\"Insert your instructions here:: '{text}'\"\n",
        "        zero_shot = zero_shot_prompting(\"Task description\", zero_shot_prompt)  # Call the zero-shot function\n",
        "\n",
        "        # Record the end time and calculate the elapsed time for this sentence\n",
        "        elapsed_time = time.time() - start_time\n",
        "\n",
        "        # Store the response in the dictionary with the index as the key\n",
        "        answers_null_shot[i] = {\n",
        "            \"Prompt\": zero_shot_prompt,\n",
        "            \"Answer\": zero_shot,\n",
        "            \"Time\": elapsed_time\n",
        "        }\n",
        "\n",
        "        # Print the time taken for this particular prompt\n",
        "        print(i, f\"Time taken: {elapsed_time:.2f} seconds\")\n",
        "        print()\n",
        "\n",
        "    # Calculate the total time taken for this participant's iteration\n",
        "    elapsed_time_for_participant = time.time() - start_time_for_participant\n",
        "\n",
        "    # Save the null-shot results for this iteration in the parent dictionary\n",
        "    answers_null_shot_all[iteration] = answers_null_shot\n",
        "    reaction_time_per_participant.append(elapsed_time_for_participant)\n",
        "\n",
        "    # Print the total time taken for the current participant\n",
        "    print(f\"Elapsed time for iteration {iteration}: {elapsed_time_for_participant:.2f} seconds\")\n",
        "    print()\n",
        "\n",
        "# Print the results for all participants\n",
        "print(answers_null_shot_all)\n",
        "\n",
        "# Calculate and print the mean reaction time per participant\n",
        "print(\"Mean reaction time per participant:\", sum(reaction_time_per_participant)/len(reaction_time_per_participant))\n"
      ],
      "metadata": {
        "id": "QGrOTCQ-KKuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the **seventh** block we save the results from all test subjects in an Excel and csv file. These files subsequently store the answers of ***MULTIPLE*** test LLMs-participants.\n",
        "\n",
        "Code is provided for both replications. According to the case study, choose the corresponding passage and comment the other one out."
      ],
      "metadata": {
        "id": "KQcBmTkKXcU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "## To save results from replication 1 (Cruz_23)\n",
        "# Dictionary to DataFrame conversion\n",
        "def dict_to_dataframe(antworten_dict):\n",
        "    rows = []\n",
        "    for iteration, prompts in antworten_dict.items():\n",
        "        for index, entry in prompts.items():\n",
        "            for val in stimuli_dict.values():\n",
        "                if val['sentences'] == entry['Prompt'].split(\": \")[-1].replace(\"'\", \"\").strip():\n",
        "                  #print(val)\n",
        "                  rows.append({\n",
        "                        \"sentences\": val['sentences'],\n",
        "                        \"target_item\": val['target_item '],\n",
        "                        \"animacy\": val['animacy'],\n",
        "                        \"congruent-gender\": val['congruent-gender'],\n",
        "                        \"status\": val['status'],\n",
        "                        \"Informant\": iteration,\n",
        "                        \"Index\": index,\n",
        "                        \"Prompt\": entry[\"Prompt\"],\n",
        "                        \"models_answer\": entry[\"Antwort\"],\n",
        "                        \"time\": entry[\"Zeit\"],\n",
        "                        \"date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "                    })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "## To sav results from replication 2 (Lombard_21)\n",
        "'''# Dictionary to DataFrame conversion\n",
        "def dict_to_dataframe(antworten_dict):\n",
        "    rows = []\n",
        "    for iteration, prompts in antworten_dict.items():\n",
        "        for index, entry in prompts.items():\n",
        "            for val in stimuli_dict.values():\n",
        "                prompt_text = entry['Prompt']\n",
        "                #print(val['target_sent'].replace(\"'\",\"\"))\n",
        "                #print(prompt_text.split(\"'non':\")[1].split(\"Si\")[0].strip().replace(\"'\", \"\"))\n",
        "                if val['target_sent'].replace(\"'\",\"\").strip() == prompt_text.split(\"'non':\")[1].split(\"Si\")[0].strip().replace(\"'\", \"\"):\n",
        "                  #print(\"yes\",val['target_sent'].replace(\"'\",\"\").strip(),prompt_text.split(\"'non':\")[1].split(\"Si\")[0].strip().replace(\"'\", \"\"))\n",
        "                  rows.append({\n",
        "                        \"neologism\": val['neologism'],\n",
        "                        \"sentences\": val['target_sent'],\n",
        "                        \"change\": val['change'],\n",
        "                        \"regularity\": val['regularity'],\n",
        "                        \"process\": val['process'],\n",
        "                        \"Informant\": iteration,\n",
        "                        \"Index\": index,\n",
        "                        \"Prompt\": entry[\"Prompt\"],\n",
        "                        \"models_answer\": entry[\"Antwort\"],\n",
        "                        \"time\": entry[\"Zeit\"],\n",
        "                        \"date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "                    })\n",
        "                else:\n",
        "                  continue\n",
        "                  #print(\"no\",val['target_sent'].replace(\"'\",\"\").strip(),prompt_text.split(\"'non':\")[1].split(\"Si\")[0].strip().replace(\"'\", \"\"))\n",
        "    return pd.DataFrame(rows)'''\n",
        "\n",
        "# Convert the dictionary to a DataFrame\n",
        "new_data_df = dict_to_dataframe(antworten_null_shot_all)\n",
        "\n",
        "# Save the DataFrame as new files\n",
        "new_data_df.to_excel('all_results.xlsx', index=False)\n",
        "new_data_df.to_csv('all_results.csv', index=False)\n",
        "\n",
        "print(\"Data successfully saved!\")\n"
      ],
      "metadata": {
        "id": "WPznhbdvP7zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Replication pipeline step 4"
      ],
      "metadata": {
        "id": "xJNbLlCYNzwY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we evaluate the results.\n",
        "\n",
        "Code is provided for both replications. According to the case study, choose the corresponding passage and comment the other one out."
      ],
      "metadata": {
        "id": "VcPAmYr-OiUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "from collections import Counter\n",
        "\n",
        "# Upload the results\n",
        "results= 'results.csv' # Adjust the name of the results document\n",
        "\n",
        "## To evaluate replication 1 (Cruz_23)\n",
        "correct = 0\n",
        "mistakes = {}\n",
        "\n",
        "# Open the CSV file\n",
        "with open(results, mode='r', encoding='utf-8') as file:\n",
        "    csv_reader = csv.reader(file)\n",
        "\n",
        "    # Optional: Get the header if the file has one\n",
        "    header = next(csv_reader, None)  # Skip the header if present\n",
        "\n",
        "    # Access and process each line\n",
        "    for row in csv_reader:\n",
        "      if row[4] == \"critical\":\n",
        "\n",
        "        if row[3] == \"feminine\":\n",
        "          if row[8] == \"la\":\n",
        "            correct +=1\n",
        "          else:\n",
        "            if row[8] != \"la\":\n",
        "              key= row[5], row[6]\n",
        "              mistakes[key] = row[1],row[2],row[3]\n",
        "\n",
        "        if row[3] == \"masculine\":\n",
        "          if row[8] == \"el\":\n",
        "            correct +=1\n",
        "          else:\n",
        "            if row[8] != \"el\":\n",
        "              key= row[5], row[6]\n",
        "              mistakes[key] = row[1],row[2],row[3]\n",
        "\n",
        "      else:\n",
        "        continue\n",
        "\n",
        "wrong_target_words = []\n",
        "for m in mistakes.values():\n",
        "  wrong_target_words.append(m[0])\n",
        "mistakes_counts = dict(Counter(wrong_target_words))\n",
        "\n",
        "whole_duration=sum(reaction_time_per_participant)\n",
        "print(\"correct\",correct)\n",
        "print(\"tot responses\", correct+len(mistakes))\n",
        "print(\"mistakes\",len(mistakes))#, \":\", mistakes)\n",
        "print(\"wrong target words\",set(wrong_target_words))\n",
        "print(\"wrong target words freq\",mistakes_counts)\n",
        "print(\"mean reaction time per participant:\", sum(reaction_time_per_participant)/len(reaction_time_per_participant))\n",
        "print(\"whole study duration:\", str(datetime.timedelta(seconds=whole_duration)))\n",
        "\n",
        "# error analysis\n",
        "male_animate=0\n",
        "female_animate=0\n",
        "male_inanimate=0\n",
        "female_inanimate=0\n",
        "for val in mistakes.values():\n",
        "  if val[2] == 'masculine' and val[1] == 'animate':\n",
        "      male_animate +=1\n",
        "  elif val[2] == 'feminine' and val[1] == 'animate':\n",
        "      female_animate +=1\n",
        "  elif val[2] == 'masculine' and val[1] == 'inanimate':\n",
        "      male_inanimate +=1\n",
        "  elif val[2] == 'feminine' and val[1] == 'inanimate':\n",
        "      female_inanimate +=1\n",
        "  else:\n",
        "    print(val)\n",
        "\n",
        "print(\"male animate\", male_animate)\n",
        "print(\"female animate\", female_animate)\n",
        "print(\"male inanimate\", male_inanimate)\n",
        "print(\"female inanimate\", female_inanimate)\n",
        "\n",
        "\n",
        "## To evaluate replication 2 (Lombard_21)\n",
        "'''correct_oui = 0\n",
        "correct_neo = 0\n",
        "fillers = 0\n",
        "fillers_wrong = 0\n",
        "mistakes = {}\n",
        "filler_mistakes = {}\n",
        "filler_error_list=[]\n",
        "\n",
        "# Open the CSV file\n",
        "with open(results, mode='r', encoding='utf-8') as file:\n",
        "    csv_reader = csv.reader(file)\n",
        "\n",
        "    # Optional: Get the header if the file has one\n",
        "    header = next(csv_reader, None)  # Skip the header if present\n",
        "\n",
        "    # Access and process each line\n",
        "    for row in csv_reader:\n",
        "        #print(row)\n",
        "        neologism = row[0].lower().strip()\n",
        "        answer = row[8].lower().strip()\n",
        "        #print(answer)\n",
        "\n",
        "        if row[2] != \"Filler\":\n",
        "\n",
        "          if answer.startswith(\"oui\"):\n",
        "            correct_oui +=1\n",
        "\n",
        "            neo = answer.split(\" \")[1].strip()\n",
        "            #print(neologism, neo)\n",
        "            if neo.startswith(neologism):\n",
        "              correct_neo +=1\n",
        "\n",
        "          else:\n",
        "            key= row[5], row[6]\n",
        "            mistakes[key] = row[0].strip(),row[2].strip(),row[3].strip(),row[4].strip()\n",
        "\n",
        "        elif row[2] == \"Filler\":\n",
        "          fillers +=1\n",
        "          if answer.startswith(\"oui\"):\n",
        "            fillers_wrong +=1\n",
        "            if row[1] not in filler_mistakes.keys():\n",
        "              filler_mistakes[row[1]] = [answer]\n",
        "            else:\n",
        "              filler_mistakes[row[1]].append(answer)\n",
        "\n",
        "            filler_error_list.append(row[1])\n",
        "\n",
        "        else:\n",
        "          print(row[1], answer)\n",
        "\n",
        "wrong_fillers_counts= dict(Counter(filler_error_list))\n",
        "wrong_target_words = []\n",
        "for m in mistakes.values():\n",
        "  wrong_target_words.append(m[0])\n",
        "mistakes_counts = dict(Counter(wrong_target_words))\n",
        "\n",
        "print(\"wrong fillers\",fillers_wrong)\n",
        "print(wrong_fillers_counts)\n",
        "\n",
        "\n",
        "whole_duration=sum(reaction_time_per_participant)\n",
        "print(\"tot responses\", correct_oui+len(mistakes))\n",
        "print(\"correct\",correct_oui)\n",
        "print(\"fillers\", fillers) #40\n",
        "print(\"mistakes\",len(mistakes), \":\", mistakes)\n",
        "print(\"wrong target words\",set(wrong_target_words))\n",
        "print(\"wrong target words freq\",mistakes_counts)\n",
        "print(\"whole study duration:\", str(datetime.timedelta(seconds=whole_duration)))\n",
        "\n",
        "# error analysis\n",
        "morph_reg=0\n",
        "morph_irreg=0\n",
        "sem_reg=0\n",
        "sem_irreg=0\n",
        "for val in mistakes.values():\n",
        "  #print(val)\n",
        "  if val[1] == 'Morphological' and val[2] == 'Irregular':\n",
        "      morph_reg +=1\n",
        "  elif val[1] == 'Morphological' and val[2] == 'Regular':\n",
        "      morph_irreg +=1\n",
        "  elif val[1] == 'Semantic' and val[2] == 'Irregular':\n",
        "      sem_reg +=1\n",
        "  elif val[1] == 'Semantic' and val[2] == 'Regular':\n",
        "      sem_irreg +=1\n",
        "  else:\n",
        "    print(val)\n",
        "\n",
        "print(\"Morphological irregular\", morph_irreg)\n",
        "print(\"Morphological regular\", morph_reg)\n",
        "print(\"Semantic irregular\", sem_irreg)\n",
        "print(\"Semantic regular\", sem_reg)'''"
      ],
      "metadata": {
        "id": "aMfdapi5kkNZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
